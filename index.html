<!DOCTYPE html>
<html lang="tr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Improving Long-Horizon Task Learning in Robots Using ACT and Task Decomposition</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
  <style>
    body {
      font-family: 'Roboto', sans-serif;
      background-color: #f4f4f4;
      margin: 0;
      padding: 0;
      color: #333;
    }
    header {
      background-color: #333;
      color: white;
      padding: 20px;
      text-align: center;
    }
    h1 {
      font-size: 36px;
      margin: 0;
    }
    section {
      padding: 20px;
      max-width: 1200px;
      margin: auto;
    }
    h2 {
      font-size: 28px;
      margin-top: 40px;
      text-align: center;
    }
    p {
      font-size: 18px;
      line-height: 1.6;
    }
    .centered-text {
      text-align: center;
    }
    .video-section {
      margin-bottom: 40px;
    }
    .video-section h3 {
      text-align: center;
    }
    iframe {
      width: 100%;
      max-width: 560px;
      height: 315px;
      display: block;
      margin: 10px auto 0 auto;
    }
  </style>
</head>
<body>

<header>
  <h1>Improving Long-Horizon Task Learning in Robots Using ACT and Task Decomposition</h1>
  <p><strong>Authors:</strong> Mücahid Barstuğan, Shimpei Masuda, Ryusuke Sagawa, and Fumio Kanehiro</p>
</header>

<section>
  <h2>ABSTRACT</h2>
  <p class="centered-text">Imitation learning is widely used to teach robots everyday tasks. Unlike standard pick-and-place or assembly operations in factories, daily tasks often involve long-term dependencies, making them more complex to learn. Successfully training robots for such long-horizon tasks requires collecting many demonstrations, which in turn demands significant human effort and time resources. Moreover, traditional imitation learning methods often struggle to capture these long-term dependencies effectively. In this study, we focused on teaching three long-horizon tasks (ziploc opening, pouring a cup, and object picking) to robot system by using small amount of data. We used the bimanual teleoperation system (ALOHA) to collect high-quality demonstrations. Two different dataset were collected for each task. Both was trained with two different training approaches (train once, progressive training) by using Action Chunking with Transformers (ACT), a state-of-the-art imitation learning method capable of capturing long-term dependencies. The first dataset contained the entire long-horizon task with a large amount of data, while the second dataset was created by task dividing, resulting in two smaller dataset. The performances of two approaches were compared on both dataset. Experimental results indicate that the proposed training approach enhances robots’ ability to learn and perform daily tasks with a small amount of data.</p>

  <h2>Evaluation Videos</h2>

  <div class="video-row">
    <div class="video-container">
      <h3>Ziploc Opening - Human View</h3>
      <iframe src="https://www.youtube.com/embed/jFJGdfSg0vY" frameborder="0" allowfullscreen></iframe>
    </div>
    <div class="video-container">
      <h3>Ziploc Opening - Robot View</h3>
      <iframe src="https://www.youtube.com/embed/w7VFbqu9m7E" frameborder="0" allowfullscreen></iframe>
    </div>
  </div>
  
  <div class="video-section">
    <h3>Cup Pouring - Human View</h3>
    <iframe src="https://www.youtube.com/embed/DjKtxG-PxdQ" frameborder="0" allowfullscreen></iframe>
  </div>
  <div class="video-section">
    <h3>Double Insertion - Human View</h3>
    <iframe src="https://www.youtube.com/embed/U1patJlzQJ0" frameborder="0" allowfullscreen></iframe>
  </div>
  <div class="video-section">
    <h3>Double Insertion - Robot View</h3>
    <iframe src="https://www.youtube.com/embed/_QBN3bay2hc" frameborder="0" allowfullscreen></iframe>
  </div>
  <div class="video-section">
    <h3>Object Picking - Human View</h3>
    <iframe src="https://www.youtube.com/embed/x4AgQnnzJMg" frameborder="0" allowfullscreen></iframe>
  </div>
  <div class="video-section">
    <h3>Object Picking - Robot View</h3>
    <iframe src="https://www.youtube.com/embed/KGTxhwOsY1E" frameborder="0" allowfullscreen></iframe>
  </div>
</section>

</body>
</html>
